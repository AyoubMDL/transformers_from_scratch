{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLMvvgYMd71Urm3vyVFNqk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyoubMDL/transformers_from_scratch/blob/main/positional_encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pIFduuxtoIj3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criteria for positional encoding :    \n",
        "1. It should output a unique encoding for each time-step \n",
        "(wordâ€™s position in a sentence)\n",
        "\n",
        "2. Distance between any two time-steps should be consistent \n",
        "across sentences with different lengths.\n",
        "\n",
        "3. Our model should generalize to longer sentences without \n",
        "any efforts. Its values should be bounded.\n",
        "\n",
        "4. It must be deterministic"
      ],
      "metadata": {
        "id": "fBQ2ZH_PrH-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positional encoding has a number of advantages : \n",
        "\n",
        "1. The sine and cosine functions have values in [-1, 1], which keeps the values of the positional encoding matrix in a normalized range.\n",
        "2. As the sinusoid for each position is different, you have a unique way of encoding each position.\n",
        "3. You have a way of measuring or quantifying the similarity between different positions, hence enabling you to encode the relative positions of words."
      ],
      "metadata": {
        "id": "KxrSst7bqQyc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The positional encoding formula is given by:\n",
        "\\begin{align*}\n",
        "PE_{(pos, 2i)} &= \\sin\\left(\\frac{{pos}}{{10000^{\\frac{{2i}}{{d_{\\text{model}}}}}}}\\right) \\\\\n",
        "PE_{(pos, 2i+1)} &= \\cos\\left(\\frac{{pos}}{{10000^{\\frac{{2i}}{{d_{\\text{model}}}}}}}\\right)\n",
        "\\end{align*}\n",
        "\n",
        "New formula :\n",
        "\n",
        "\\begin{align*}\n",
        "PE_{(pos, i)} &= \\sin\\left(\\frac{{pos}}{{10000^{\\frac{{i}}{{d_{\\text{model}}}}}}}\\right)\\ when\\ i\\ is\\ even \\\\ \n",
        "PE_{(pos, i)} &= \\cos\\left(\\frac{{pos}}{{10000^{\\frac{{i-1}}{{d_{\\text{model}}}}}}}\\right)\\ when\\ i\\ is\\ odd\n",
        "\\end{align*}\n"
      ],
      "metadata": {
        "id": "QWyud9vfqMU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 10\n",
        "d_model = 6"
      ],
      "metadata": {
        "id": "HOaXOpwyqI7q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "even_i = torch.arange(0, d_model, 2).float()\n",
        "even_i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwowGzt3qLpv",
        "outputId": "9594c303-8315-4367-b92c-718cb6eb8508"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "even_denominator = torch.pow(10000, even_i/d_model)\n",
        "even_denominator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95PySpqnsD6K",
        "outputId": "26bc9045-2642-4ef8-f5e2-b447fd975837"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  1.0000,  21.5443, 464.1590])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "odd_i = torch.arange(1, d_model, 2).float()\n",
        "odd_i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6XKv0i7rw1u",
        "outputId": "fe0844cd-1853-43c5-e3e7-2158587cc369"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 3., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "odd_denominator = torch.pow(10000, (odd_i - 1)/d_model)\n",
        "odd_denominator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Or49EeGsAY6",
        "outputId": "ca9bec41-b6fb-4916-af77-f353cfef398f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  1.0000,  21.5443, 464.1590])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "denominator = even_denominator"
      ],
      "metadata": {
        "id": "vprUXv8dsaoD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "denominator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWxp3auk4rAg",
        "outputId": "4324136a-9b79-448d-a5b4-49003250768e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  1.0000,  21.5443, 464.1590])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "position = torch.arange(max_seq_length, dtype=torch.float).reshape(max_seq_length, 1)\n",
        "position"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuI5dDH2ssgz",
        "outputId": "cb4d7296-e835-4d30-d45a-b7d9416eb22f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [4.],\n",
              "        [5.],\n",
              "        [6.],\n",
              "        [7.],\n",
              "        [8.],\n",
              "        [9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "even_pe = torch.sin(position/ denominator)\n",
        "odd_pe = torch.cos(position / denominator)"
      ],
      "metadata": {
        "id": "PPBuqUhUs29L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "even_pe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EurksUDUs74C",
        "outputId": "ea9cf5a1-ce60-4c6f-b999-531080cf5d7d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.8415,  0.0464,  0.0022],\n",
              "        [ 0.9093,  0.0927,  0.0043],\n",
              "        [ 0.1411,  0.1388,  0.0065],\n",
              "        [-0.7568,  0.1846,  0.0086],\n",
              "        [-0.9589,  0.2300,  0.0108],\n",
              "        [-0.2794,  0.2749,  0.0129],\n",
              "        [ 0.6570,  0.3192,  0.0151],\n",
              "        [ 0.9894,  0.3629,  0.0172],\n",
              "        [ 0.4121,  0.4057,  0.0194]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "odd_pe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBoo7vFytSfC",
        "outputId": "8a82b93d-4f16-4f1d-e856-c0647d372f50"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0000,  1.0000,  1.0000],\n",
              "        [ 0.5403,  0.9989,  1.0000],\n",
              "        [-0.4161,  0.9957,  1.0000],\n",
              "        [-0.9900,  0.9903,  1.0000],\n",
              "        [-0.6536,  0.9828,  1.0000],\n",
              "        [ 0.2837,  0.9732,  0.9999],\n",
              "        [ 0.9602,  0.9615,  0.9999],\n",
              "        [ 0.7539,  0.9477,  0.9999],\n",
              "        [-0.1455,  0.9318,  0.9999],\n",
              "        [-0.9111,  0.9140,  0.9998]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "even_pe.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxFQk6QWtV8y",
        "outputId": "e92d5d31-aa5f-4206-ce28-6b1010c21a95"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked = torch.stack([even_pe, odd_pe], dim=2)\n",
        "stacked.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXciWsxwte0K",
        "outputId": "2c4b61a4-9678-41fd-ecdd-9493873c0939"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvjn7gtq7F1Z",
        "outputId": "0687f870-de52-4252-ec28-3bde95c54c15"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000,  1.0000],\n",
              "         [ 0.0000,  1.0000],\n",
              "         [ 0.0000,  1.0000]],\n",
              "\n",
              "        [[ 0.8415,  0.5403],\n",
              "         [ 0.0464,  0.9989],\n",
              "         [ 0.0022,  1.0000]],\n",
              "\n",
              "        [[ 0.9093, -0.4161],\n",
              "         [ 0.0927,  0.9957],\n",
              "         [ 0.0043,  1.0000]],\n",
              "\n",
              "        [[ 0.1411, -0.9900],\n",
              "         [ 0.1388,  0.9903],\n",
              "         [ 0.0065,  1.0000]],\n",
              "\n",
              "        [[-0.7568, -0.6536],\n",
              "         [ 0.1846,  0.9828],\n",
              "         [ 0.0086,  1.0000]],\n",
              "\n",
              "        [[-0.9589,  0.2837],\n",
              "         [ 0.2300,  0.9732],\n",
              "         [ 0.0108,  0.9999]],\n",
              "\n",
              "        [[-0.2794,  0.9602],\n",
              "         [ 0.2749,  0.9615],\n",
              "         [ 0.0129,  0.9999]],\n",
              "\n",
              "        [[ 0.6570,  0.7539],\n",
              "         [ 0.3192,  0.9477],\n",
              "         [ 0.0151,  0.9999]],\n",
              "\n",
              "        [[ 0.9894, -0.1455],\n",
              "         [ 0.3629,  0.9318],\n",
              "         [ 0.0172,  0.9999]],\n",
              "\n",
              "        [[ 0.4121, -0.9111],\n",
              "         [ 0.4057,  0.9140],\n",
              "         [ 0.0194,  0.9998]]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pe = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "pe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTQQUbOFt8AM",
        "outputId": "04c8dfcb-394c-4ce2-83ba-e3c0b9fc00ea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
              "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
              "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
              "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000],\n",
              "        [-0.7568, -0.6536,  0.1846,  0.9828,  0.0086,  1.0000],\n",
              "        [-0.9589,  0.2837,  0.2300,  0.9732,  0.0108,  0.9999],\n",
              "        [-0.2794,  0.9602,  0.2749,  0.9615,  0.0129,  0.9999],\n",
              "        [ 0.6570,  0.7539,  0.3192,  0.9477,  0.0151,  0.9999],\n",
              "        [ 0.9894, -0.1455,  0.3629,  0.9318,  0.0172,  0.9999],\n",
              "        [ 0.4121, -0.9111,  0.4057,  0.9140,  0.0194,  0.9998]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pe.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkTxOPAcuaJ6",
        "outputId": "f1d46b65-1d93-4481-f0c7-36ea2c84850a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_length):\n",
        "        super().__init__()\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self):\n",
        "        even_i = torch.arange(0, self.d_model, 2).float()\n",
        "        denominator = torch.pow(10000, even_i/self.d_model)\n",
        "        position = torch.arange(self.max_seq_length).reshape(self.max_seq_length, 1)\n",
        "        even_pe = torch.sin(position / denominator)\n",
        "        odd_pe = torch.cos(position/ denominator)\n",
        "        stacked = torch.stack([even_pe, odd_pe], dim=2)\n",
        "        pe = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "\n",
        "        return pe"
      ],
      "metadata": {
        "id": "EEizOvtXucc7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pe = PositionalEncoding(d_model=512, max_seq_length=12)\n",
        "pe.forward().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgQZsKlnzFQT",
        "outputId": "aec91b24-4e97-4d57-db21-a8e01b5fe697"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}